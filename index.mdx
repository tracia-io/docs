---
title: Introduction
description: Store, test, and trace LLM prompts with Tracia
---

Tracia is a prompt management platform that helps you store, version, test, and trace your LLM prompts. Move prompts out of your codebase and into a central location where they can be managed, tested, and monitored.

## Why Tracia?

<CardGroup cols={2}>
  <Card title="Prompt Versioning" icon="code-branch">
    Track changes to your prompts over time. Roll back to previous versions when needed.
  </Card>
  <Card title="Variable Templates" icon="brackets-curly">
    Use `{{variable}}` syntax to create reusable prompts with dynamic content.
  </Card>
  <Card title="Tracing & Analytics" icon="chart-line">
    Monitor latency, token usage, and costs for every prompt execution.
  </Card>
  <Card title="Multi-Provider Support" icon="plug">
    Connect OpenAI, Anthropic, and Google LLM providers.
  </Card>
</CardGroup>

## How It Works

1. **Create prompts** in the Tracia dashboard with versioning and variable support
2. **Install the SDK** in your application
3. **Run prompts** via the SDK - Tracia handles template rendering and LLM calls
4. **Monitor traces** to track performance and debug issues

## Quick Example

```typescript
import { Tracia } from 'tracia';

const tracia = new Tracia({ apiKey: process.env.TRACIA_API_KEY });

const result = await tracia.prompts.run('welcome-email', {
  name: 'Alice',
  product: 'Tracia'
});

console.log(result.text);
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Quickstart" icon="rocket" href="/quickstart">
    Get up and running in 5 minutes
  </Card>
  <Card title="SDK Reference" icon="book" href="/sdk-node/prompts">
    Explore the full SDK API
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/introduction">
    Direct REST API documentation
  </Card>
</CardGroup>
